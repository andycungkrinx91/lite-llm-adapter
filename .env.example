# Environment: 'dev' for development (uses model_config_dev.json), 'prod' for production
ENVIRONMENT=dev

# The model ID to use if none is specified in the API request.
DEFAULT_MODEL_ID=qwen3-0.6b

# The base path where GGUF model files are stored.
# For Docker, this path is inside the container.
MODEL_BASE_PATH=/app/models/gguf_models

# Connection URL for the Redis server.
# For Docker Compose, use 'redis://redis:6379'. For native, use 'redis://localhost:6379'.
REDIS_URL=redis://redis:6379

# A prefix for all Redis keys to avoid collisions if Redis is shared.
REDIS_KEY_PREFIX=llm_adapter

# Number of CPU threads for llama.cpp to use for inference.
# Recommended: Set to the number of physical CPU cores.
CPU_THREADS=8

# A secret bearer token for API authentication.
# Replace with a long, random string.
AUTH=your-secret-token-here

# The maximum number of requests that can be processed concurrently.
# Set to 1 to process requests sequentially.
MAX_CONCURRENT_REQUESTS=1
