# --- Environment Configuration ---
# Copy this file to .env and fill in the values.

# Set to 'dev' or 'prod' to load the corresponding model config file.
ENVIRONMENT=dev

# The model to use if one isn't specified in the API request. Must match an 'id' in the model config.
DEFAULT_MODEL_ID=qwen3-0.6b

MODEL_BASE_PATH=/app/models/gguf_models
REDIS_URL=redis://localhost:6379
# A prefix for all Redis keys to avoid conflicts with other applications.
REDIS_KEY_PREFIX=llm_adapter
# The number of threads for llama.cpp to use for inference.
CPU_THREADS=4
# This is CRITICAL for controlling CPU usage. It tells the underlying OpenBLAS
# math library how many threads to use. Set this to the same value as CPU_THREADS.
OPENBLAS_NUM_THREADS=4
AUTH=your-super-secret-token-change-me

# The number of simultaneous requests the service can process. Others queue in Redis.
# For memory-constrained systems (e.g., < 16GB RAM), it is CRITICAL to set this to 1
# to prevent out-of-memory errors when running larger models (7B+).
MAX_CONCURRENT_REQUESTS=1
